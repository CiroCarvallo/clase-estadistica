---
title: "REGRESION LINEAL VINOS"
output:
  html_document:
    df_print: paged
---

Tenemos 1000 vinos a los cuales les medimos 11 variables de interés: fixed acidity, volatile
acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide,
density, pH, sulphates y alcohol. A su vez, cada uno de estos vinos fue calificado con una nota
del 0 al 10 por unos especialistas (que al calificarlos tuvieron en cuenta ´unicamente su "experiencia
sensorial"). Estos datos fueron guardados en la variable quality.
El objetivo de este TP es poder explicar mediante una regresión lineal la variable respuesta quality
en función de las 11 variables explicativas ya mencionadas.

```{r}
# cargo los datos
library(caret)
library(glmnet)
library(glmnetUtils)
vinos <- read.csv("vinos_1.csv",header=TRUE,sep=",")

```

# PREPROCESAR

```{r}
boxplot(vinos)
```


```{r}
reemplazar_outliers=function(x){
  # reemplaza los outliers por el valor del quantile .02 y .98 segun corresponda.
  qnt <- quantile(x,probs=c(.25,.75))
  alfa <- quantile(x,probs=c(.02,0.98))
  H<-1.5*IQR(x)
  #x[x< (qnt[1]-H)]<-alfa[1]
  #x[x>(qnt[2]+H)]<-alfa[2]
  x[x<alfa[1]]<-alfa[1]
  x[x>alfa[2]]<-alfa[2]
  return(x)
}
preprocesar=function(data){
  
  for (i in 1:(length(data))){
    data[,i]=reemplazar_outliers(data[,i])
    #data[,i]=as.numeric(scale(data[,i],center= TRUE, scale= TRUE))
  }
  return(data)
}

# reemplazo los outliers en todas las columnas
data <- preprocesar(vinos)
boxplot(data)
```

# VISUALIZACIÓN

```{r}
plot(data)

```
```{r}
# hago scatter plots para visualizar la relacion entre quality y las variables

graficar <- function(variable){
  scatter.smooth(variable,y=data$quality,main= "quality ~",lpars =
                   list(col = "red", lwd = 3, lty = 3))
}

cor(data$quality,data$fixed.acidity)
graficar(data$fixed.acidity)

cor(data$quality,data$volatile.acidity)
graficar(data$volatile.acidity)

cor(data$quality,data$citric.acid)
graficar(data$citric.acid)

cor(data$quality,data$total.sulfur.dioxide)
graficar(data$total.sulfur.dioxide)

cor(data$alcohol,data$quality)
graficar(data$alcohol)

```

# MODELOS

```{r}
set.seed(42)
```
### SEPARO EN TRAIN Y TEST
```{r}
Y <- vinos[,"quality"]
train_indices<-createDataPartition(Y,p=0.8,list=FALSE) # mantiene la proporción de las clases de Y
vinos_train<- data[train_indices,]
vinos_test <- data[-train_indices,]
vinos_test_original<-vinos[-train_indices,]

```

En cada modelo voy a ver el MSE de vinos_train, vinos_test  y tambien MSE vinos_test_original porque aunque quiero entrenar el modelo con datos que no tengan outliers en "quality", la variable quality de vinos_2 seguramente tambien tenga outliers y por lo tanto para testear el modelo puede ser conveniente darle más importancia al error de la prediccion con la variable quality original.  

### MODELO 1

El primer modelo consiste en simplemente entrenar al modelo lineal usando todas las variables.

```{r}

# defino train control para k fold cross validation

train_control<-trainControl(method = "cv",number = 10)

# entreno el modelo lineal

vinos.fit <-train(quality ~., data = vinos_train, trControl=train_control, method = "lm")

# medidas promedio de los 10 folds. En particular MSE es la medida que uso para decidir cual
# es el modelo lineal que mejor ajusta

vinos.fit$results

# calculo MSE del modelo con vinos_train
MSE=(vinos.fit$results$RMSE)^2
MSE

# resumen del modelo final
modeloFinal1 <- vinos.fit$finalModel
summary(modeloFinal1)

plot(modeloFinal1$fitted.values,modeloFinal1$residuals)

prediccion<-predict(modeloFinal1,vinos_test)
MSE<-mean((vinos_test[,"quality"]-prediccion)^2)
MSE

prediccion<-predict(modeloFinal1,vinos_test)
MSE<-mean((vinos_test_original[,"quality"]-prediccion)^2)
MSE
```
### MISMO MODELO CON REGRESION LINEAL PENALIZADA

El primer modelo puede pensarse como regresión lineal penalizada con lambda=0

```{r}
### PRUEBO EL MISMO MODELO CON REGRESIÓN LINEAL PENALIZADA

foldid=sample(1:10,size=length(vinos_train[,"quality"]),replace=TRUE)
# realizo cross-validation para elegir lambda con 3 valores de alpha fijos.

cv.alpha0 <- cv.glmnet(quality~ ., data=vinos_train,foldid=foldid,alpha=0) # Ridge
cv.alpha05 <- cv.glmnet(quality~ ., data=vinos_train,foldid=foldid,alpha=0.5)
cv.alpha1 <- cv.glmnet(quality~ ., data=vinos_train,foldid=foldid,alpha=1) # Lasso

plot(cv.alpha0)
plot(cv.alpha05)
plot(cv.alpha1)
```

Elijo el modelo con alpha=1 y lambda = lambda.1se porque este tiene solo 4 variables diferente de 0 y el MSE es similar al del lambda que minimiza el MSE en vinos_train. Los coeficientes no nulos son los siguientes

```{r}
coef(cv.alpha1, s="lambda.1se")
```
El MSE para vinos_test es 
```{r}
prediccion <-predict(cv.alpha1, newdata=vinos_test, s = "lambda.1se")
MSE<-mean((vinos_test[,"quality"]-prediccion)^2)
MSE

prediccion <-predict(cv.alpha1, newdata=vinos_test, s = "lambda.1se")
MSE<-mean((vinos_test_original[,"quality"]-prediccion)^2)
MSE
```


### MODELO 2

El segundo modelo utiliza las variables que tienen p-valor más chico que 0.05 en el MODELO 1 y también utiliza intercept.
El modelo intenta explicar quality a partir de volatile.acidity,citric.acid, chlorides, total.sulfur.dioxide, sulphates, alcohol.

```{r}

# defino train control para k fold cross validation

train_control<-trainControl(method = "cv",number = 10)

# entreno el modelo lineal

vinos.fit <-train(quality ~ volatile.acidity + citric.acid + chlorides + total.sulfur.dioxide + sulphates + alcohol,
                   data = vinos_train, trControl=train_control,method ="lm")                  

# medidas promedio de los 10 folds.

vinos.fit$results

# calculo MSE del modelo con vinos_train
MSE=(vinos.fit$results$RMSE)^2
MSE

# resumen del modelo final
modeloFinal2 <- vinos.fit$finalModel
summary(modeloFinal2)

plot(modeloFinal2$fitted.values,modeloFinal2$residuals)


prediccion<-predict(modeloFinal2,vinos_test)
MSE<-mean((vinos_test[,"quality"]-prediccion)^2)
MSE

prediccion<-predict(modeloFinal2,vinos_test)
MSE<-mean((vinos_test_original[,"quality"]-prediccion)^2)
MSE
```

Este modelo no solo obtiene un RME en en vinos_test similar al del modelo1, sino que lo hace explicando quality con variables para las cuales se tiene evidencia de que el parametro que las acompaña no es 0. Al disminuir la cantidad de variables y restringirnos a utilizar aquellas que son significativas, sería razonable que esto ayude a que overfitting no sea un problema. 

## MODELO 3
El modelo se usa las variables del modelo 2 pero agrega dependencia cuadratrica de las mismas.

```{r}
foldid=sample(1:10,size=length(vinos_train[,"quality"]),replace=TRUE)
# realizo cross-validation para elegir lambda con 3 valores de alpha fijos.

cv.alpha0 <- cv.glmnet(quality~ volatile.acidity + citric.acid +chlorides + total.sulfur.dioxide + sulphates + alcohol + I(volatile.acidity^2) + I(citric.acid^2)+ I(chlorides^2) + I(total.sulfur.dioxide^2)+ I(sulphates^2) + I(alcohol^2), data=vinos_train,foldid=foldid,alpha=0) # Ridge

cv.alpha05 <- cv.glmnet(quality~ volatile.acidity + citric.acid +chlorides + total.sulfur.dioxide + sulphates + alcohol + I(volatile.acidity^2) + I(citric.acid^2)+ I(chlorides^2) + I(total.sulfur.dioxide^2)+ I(sulphates^2) + I(alcohol^2), data=vinos_train,foldid=foldid,alpha=0.5)

cv.alpha1 <- cv.glmnet(quality~ volatile.acidity + citric.acid +chlorides + total.sulfur.dioxide + sulphates + alcohol + I(volatile.acidity^2) + I(citric.acid^2)+ I(chlorides^2) + I(total.sulfur.dioxide^2)+ I(sulphates^2) + I(alcohol^2), data=vinos_train,foldid=foldid,alpha=1) # Lasso

plot(cv.alpha0)
plot(cv.alpha05)
plot(cv.alpha1)
```
Elijo el modelo con alpha=0.5 y lambda = lambda.min. Los coeficientes no nulos son los siguientes

```{r}
coef(cv.alpha05, s="lambda.min")
```
El MSE para vinos_test es 
```{r}
prediccion <-predict(cv.alpha05, newdata=vinos_test, s = "lambda.min")
MSE<-mean((vinos_test[,"quality"]-prediccion)^2)
MSE

prediccion <-predict(cv.alpha05, newdata=vinos_test, s = "lambda.min")
MSE<-mean((vinos_test_original[,"quality"]-prediccion)^2)
MSE

```



## MODELO 4

En este modelo, considero que el logaritmo(quality) depende linealmente de las variables.
```{r}

# defino train control para k fold cross validation

train_control<-trainControl(method = "cv",number = 10)

# entreno el modelo lineal

vinos.fit <-train(log(quality) ~.,
                   data = vinos_train, trControl=train_control,method ="lm")                  

# medidas promedio de los 10 folds. 

vinos.fit$results

# resumen del modelo final
modeloFinal4 <- vinos.fit$finalModel
summary(modeloFinal4)

# MSE de train_vinos
MSE <- mean((vinos_train[,"quality"]-exp(modeloFinal4$fitted.values))^2)
MSE
plot(modeloFinal4$fitted.values,modeloFinal4$residuals)

# MSE de test_vinos
MSE <- mean((vinos_test[,"quality"]-exp(predict(modeloFinal4,vinos_test)))^2)
MSE

MSE <- mean((vinos_test_original[,"quality"]-exp(predict(modeloFinal4,vinos_test)))^2)
MSE
```

## MODELO 5

El último modelo considera "volatile.acidity", "citric.acid", "chlorides", "total.sulfur.dioxide", "sulphates","alcohol","pH" y el producto de estas variables.

```{r}
vinos_train5 <- vinos_train[,match(c("volatile.acidity","citric.acid","chlorides","total.sulfur.dioxide","sulphates","alcohol","pH","quality"),colnames(vinos))]
vinos_test5 <- vinos_test[,match(c("volatile.acidity","citric.acid","chlorides","total.sulfur.dioxide","sulphates","alcohol","pH","quality"),colnames(vinos))]
l=1
for (i in 1:6){
  for (j in (i+1):7){
    vinos_train5[,8+l]<-vinos_train5[,i]*vinos_train5[,j]
    vinos_test5[,8+l]<-vinos_test5[,i]*vinos_test5[,j]
    l<-l+1
  }
}


foldid=sample(1:10,size=length(vinos_train5[,"quality"]),replace=TRUE)
cv.alpha0 <- cv.glmnet(quality~ ., data=vinos_train5,foldid=foldid,alpha=0) # Ridge
cv.alpha05 <- cv.glmnet(quality~ ., data=vinos_train5,foldid=foldid,alpha=0.5)
cv.alpha1 <- cv.glmnet(quality~ ., data=vinos_train5,foldid=foldid,alpha=1) # Lasso


plot(cv.alpha0)
plot(cv.alpha05)
plot(cv.alpha1)
```

Elijo el modelo con alpha=1 y lambda = lambda.min

```{r}
#MSE vinos_train
MSE<-cv.alpha1$cvm[match(cv.alpha1$lambda.min,cv.alpha1$lambda)]
MSE
coef(cv.alpha1, s="lambda.min")
```
El MSE para vinos_test es 
```{r}
prediccion <-predict(cv.alpha1, newdata=vinos_test5, s = "lambda.min")
MSE<-mean((vinos_test5[,"quality"]-prediccion)^2)
MSE

prediccion <-predict(cv.alpha1, newdata=vinos_test5, s = "lambda.min")
MSE<-mean((vinos_test_original[,"quality"]-prediccion)^2)
MSE
```
# ELECCION DE MODELO

como el MSE de vinos_test para el modelo5 es el mas chico, elijo este como el modelo final
```{r}

vinos_prediccion <- read.csv("vinos_2.csv",header=TRUE,sep=",")
preprocesa=function(data){
  
  for (i in 1:(length(data))){
    data[,i]=reemplazar_outliers(data[,i])
  }
  return(data)
}
vinos_prediccion <- preprocesa(vinos_prediccion)
x=c("volatile.acidity","citric.acid","chlorides","total.sulfur.dioxide","sulphates","alcohol","pH")

vinos_p <- vinos_prediccion[,x]
vinos_p[,"quality"]<-1:599 # pongo cualquier cosa solo para que tenga "quality"
l<-1
for (i in 1:6){
  for (j in (i+1):7){
    vinos_p[,8+l]<-vinos_p[,i]*vinos_p[,j]
    vinos_p[,8+l]<-vinos_p[,i]*vinos_p[,j]
    l<-l+1
  }
}
predichos <-predict(cv.alpha1, newdata=vinos_p, s = "lambda.min")
round(predichos,3)
write.csv(round(predichos,3), file = "predichos.csv",row.names = FALSE)

```



